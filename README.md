ğŸš€ Synapse-Agent-Fabric

ğŸ¤– Your Production-Ready Personal Agentic AI Chatbot

Synapse-Agent-Fabric is an advanced, production-grade GenAI application built on a cutting-edge agentic architecture. It empowers users to create custom AI agents, seamlessly switch between multiple LLM providers (like Groq and OpenAI), and even enable real-time web search to fetch live information.

This modular and scalable system is designed for performance, flexibility, and ease of use, making it perfect for developers, researchers, and AI enthusiasts.

ğŸ§© System Overview

The project is built on a three-tier architecture, ensuring clear separation of responsibilities:

1ï¸âƒ£ Core AI Agent (LangGraph) â€“ The intelligent engine powering your AI chatbot.
2ï¸âƒ£ Backend Server (FastAPI) â€“ The high-performance API layer bridging UI and AI.
3ï¸âƒ£ User Interface (Streamlit) â€“ A sleek, interactive web application for effortless interaction.

âœ¨ Key Features

âœ… Custom Agent Behavior â€“ Configure your agent with a system prompt (e.g., â€œAct as a Financial Analystâ€).
âœ… Multi-LLM Support â€“ Switch between Groqâ€™s lightning-fast models and OpenAIâ€™s powerful models.
âœ… Dynamic Model Selection â€“ Choose models like qwen, gemma, or gpt-4o-mini on the fly.
âœ… Real-Time Web Search â€“ Fetch live internet data with Tavily API integration.
âœ… Scalable & Robust Architecture â€“ Built with LangGraph and FastAPI for stability and flexibility.
âœ… Modern UI â€“ A clean, minimal, and user-friendly interface designed in Streamlit.

ğŸ› ï¸ Tech Stack
Layer	Tools & Technologies
AI Agent	LangChain, LangGraph (ReAct Agent)
Backend	FastAPI, Uvicorn
Frontend	Streamlit
LLM Providers	Groq, OpenAI
Search Integration	Tavily Search
Language	Python
ğŸ—ï¸ Architecture & Layout

This project is designed with modularity in mind, making it easy to maintain and extend.

ğŸ“‚ Phase 1: Core AI Agent (ai_agent.py)

Implements create_react_agent from LangGraph for tool-using AI agents.

ğŸ“‚ Phase 2: Backend Server (backend.py)

FastAPI-powered REST API.

Uses Pydantic for validation and connects directly to the AI agent.

ğŸ“‚ Phase 3: User Interface (frontend.py)

Streamlit web app for easy interaction.

Provides model selection, agent customization, and query execution.

ğŸ–¼ï¸ Architecture Diagram

(Insert Architecture Diagram Here)

ğŸ“¸ In Action

ğŸ”¹ Model Selection (Groq Provider) â€“ Choose a model and start chatting instantly.
ğŸ”¹ Agent Customization â€“ Build domain-specific agents like Financial Analysts, Data Scientists, or Research Bots.

ğŸš€ Getting Started
1ï¸âƒ£ Install Dependencies

Create a requirements.txt and install:

streamlit
fastapi
uvicorn
python-dotenv
requests
langchain
langchain-groq
langchain-openai
langchain-tavily
langgraph


Then run:

pip install -r requirements.txt

2ï¸âƒ£ Configure API Keys

In your project root, create a .env file:

GROQ_API_KEY="gsk_xxxxxxxxxxxxxxxxxxxxxx"
TAVILY_API_KEY="tvly-xxxxxxxxxxxxxxxxxxxxx"
OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxx"

3ï¸âƒ£ Run the Application

Terminal 1: Start Backend Server

python backend.py


Server runs at: http://127.0.0.1:9999

Terminal 2: Start Frontend

python -m streamlit run frontend.py


Your chatbot UI will open in a browser tab.

ğŸ¯ Why Synapse-Agent-Fabric?

âš¡ Lightning-fast inference with Groq models.

ğŸŒ Live web search capability.

ğŸ§© Plug-and-play modularity for scaling.

ğŸ› ï¸ Developer-friendly design with clean architecture.

Start building your own agent-powered GenAI ecosystem today! ğŸš€
